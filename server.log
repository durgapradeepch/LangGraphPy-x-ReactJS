INFO:     llm_client.py:35    - âœ… LLM client initialized with model: gpt-4o
INFO:     cust_logger.py:68    - Set message color for graph.py to MAGENTA
INFO:     cust_logger.py:68    - Set message color for server.py to PURPLE
INFO:     server.py:53    - {"timestamp": "2025-12-01T17:54:26.203087", "uuid": null, "received": {"uuid": "graph-stone-middle-through", "init": true}}
INFO:     server.py:64    - {"timestamp": "2025-12-01T17:54:26.203482", "uuid": "graph-stone-middle-through", "op": "Initializing ws with client."}
INFO:     server.py:53    - {"timestamp": "2025-12-01T17:54:59.124051", "uuid": "graph-stone-middle-through", "received": {"uuid": "graph-stone-middle-through", "message": "Audit all changes in the last 24 hours - show me changelogs, deployments, and who made them", "init": false}}
INFO:     graph.py:118   - ğŸš€ Using enhanced workflow for: Audit all changes in the last 24 hours - show me c...
INFO:     workflow.py:162   - ğŸš€ Processing: 'Audit all changes in the last 24 hours - show me changelogs, deployments, and who made them'
INFO:     workflow.py:72    - ğŸ¯ Orchestrator: Starting workflow
INFO:     mcp_client.py:251   - âœ… Created MCP client for session default
INFO:     mcp_client.py:190   - ğŸ“‹ Fetching available MCP tools
INFO:     mcp_client.py:56    - âœ… Fetched 47 MCP tools from server
INFO:     workflow.py:79    - ğŸ“‹ Loaded 47 available MCP tools
INFO:     orchestrator.py:36    - ğŸ¯ Orchestrator validating workflow for session graph-stone-middle-through
INFO:     orchestrator.py:41    - ğŸ” State validation: âœ… PASSED
INFO:     orchestrator.py:55    - âœ… Orchestrator validation passed
INFO:     workflow.py:98    - ğŸ” Query Analysis: Analyzing user query
INFO:     query_analysis_agent.py:26    - ğŸ” Analyzing query: 'Audit all changes in the last 24 hours - show me c...'
INFO:     llm_client.py:114   - ğŸ” Query analyzed: exploration with confidence 0.9
INFO:     llm_client.py:257   - ğŸ“‹ Tool plan created: 2 tools planned
INFO:     query_analysis_agent.py:44    - ğŸ“‹ Tool plan: [
  {
    "name": "search_changelogs",
    "parameters": {
      "description": "last 24 hours"
    }
  },
  {
    "name": "search_changelogs_by_event_type",
    "parameters": {
      "event_type": "deployment"
    }
  }
]
INFO:     query_analysis_agent.py:64    - âœ… Query analyzed: type=exploration, confidence=0.9
INFO:     workflow.py:103   - ğŸ› ï¸ Tool Execution: Executing MCP tools
INFO:     tool_execution_agent.py:37    - ğŸ› ï¸ Executing 2 tools
INFO:     tool_execution_agent.py:92    - ğŸ”§ Executing search_changelogs (attempt 1/2)
INFO:     mcp_client.py:251   - âœ… Created MCP client for session graph-stone-middle-through
INFO:     mcp_client.py:87    - ğŸ”§ Executing MCP tool: search_changelogs
INFO:     mcp_client.py:93    - âœ… Tool search_changelogs executed successfully
INFO:     tool_execution_agent.py:92    - ğŸ”§ Executing search_changelogs_by_event_type (attempt 1/2)
INFO:     mcp_client.py:87    - ğŸ”§ Executing MCP tool: search_changelogs_by_event_type
INFO:     mcp_client.py:93    - âœ… Tool search_changelogs_by_event_type executed successfully
INFO:     tool_execution_agent.py:60    - âœ… Tool execution completed: 100.00% success rate
INFO:     workflow.py:122   - âœ¨ Response Enrichment: Enriching response
INFO:     response_enrichment_agent.py:26    - âœ¨ Enriching response
INFO:     response_enrichment_agent.py:30    - ğŸ¤– Calling LLM to generate enriched response...
INFO:     response_enrichment_agent.py:35    - ğŸŒŠ Using streaming mode for response generation
INFO:     llm_client.py:288   - ğŸ”§ Preprocessing tool: search_changelogs, result keys: ['changelogs', 'count', 'count_is_exact', 'is_limited', 'page', 'page_size', 'timestamp', 'tool', 'parameters', 'success']
INFO:     llm_client.py:480   - âš ï¸ No preprocessing applied for tool: search_changelogs
INFO:     llm_client.py:288   - ğŸ”§ Preprocessing tool: search_changelogs_by_event_type, result keys: ['event_type', 'changelogs', 'count', 'page', 'page_size', 'timestamp', 'tool', 'parameters', 'success']
INFO:     llm_client.py:480   - âš ï¸ No preprocessing applied for tool: search_changelogs_by_event_type
INFO:     llm_client.py:509   - Processing 2 successful tool results with search_terms: []
INFO:     llm_client.py:514   - ğŸ“Š Preprocessed tool data size: 651 bytes (0.6 KB)
INFO:     llm_client.py:530   - ğŸ“Š Context JSON size: 1097 bytes (1.1 KB)
INFO:     llm_client.py:531   - ğŸ“Š Estimated tokens: ~274.25 (rough estimate)
INFO:     llm_client.py:607   - Invoking LLM for response generation...
INFO:     llm_client.py:617   - Streaming completed, total length: 639
INFO:     response_enrichment_agent.py:41    - ğŸ” LLM response type: <class 'dict'>, value: {'final_response': "I checked for changes in the last 24 hours, including changelogs and deployments, but here's what I found:\n\nâ€¢ **Changelogs**: There were no changelogs recorded in the last 24 hou
INFO:     response_enrichment_agent.py:54    - ğŸ“ LLM generated response: 639 chars
INFO:     response_enrichment_agent.py:86    - âœ… Response enrichment completed with 5 forward links
INFO:     workflow.py:137   - ğŸ¯ Orchestrator: Finalizing workflow
INFO:     workflow.py:183   - âœ… Processing completed successfully
INFO:     graph.py:141   - {"timestamp": "2025-12-01T17:55:10.484078", "uuid": "graph-stone-middle-through", "llm_method": "enhanced_workflow", "sent": "I checked for changes in the last 24 hours, including changelogs and deployments, but here's what I "}
