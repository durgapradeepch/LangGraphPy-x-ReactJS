INFO:     llm_client.py:35    - âœ… LLM client initialized with model: gpt-4o
INFO:     cust_logger.py:68    - Set message color for graph.py to MAGENTA
INFO:     cust_logger.py:68    - Set message color for server.py to PURPLE
INFO:     server.py:53    - {"timestamp": "2025-12-01T22:51:34.184765", "uuid": null, "received": {"uuid": "earlier-plate-compound-shop", "init": true}}
INFO:     server.py:64    - {"timestamp": "2025-12-01T22:51:34.185127", "uuid": "earlier-plate-compound-shop", "op": "Initializing ws with client."}
INFO:     server.py:53    - {"timestamp": "2025-12-01T22:51:59.292700", "uuid": "earlier-plate-compound-shop", "received": {"uuid": "earlier-plate-compound-shop", "message": "What incidents have been open the longest without resolution and what's blocking them?", "init": false}}
INFO:     graph.py:118   - ğŸš€ Using enhanced workflow for: What incidents have been open the longest without ...
INFO:     workflow.py:179   - ğŸš€ Processing: 'What incidents have been open the longest without resolution and what's blocking them?'
INFO:     workflow.py:73    - ğŸ¯ Orchestrator: Starting workflow
INFO:     mcp_client.py:251   - âœ… Created MCP client for session default
INFO:     mcp_client.py:190   - ğŸ“‹ Fetching available MCP tools
INFO:     mcp_client.py:56    - âœ… Fetched 47 MCP tools from server
INFO:     workflow.py:80    - ğŸ“‹ Loaded 47 available MCP tools
INFO:     orchestrator.py:36    - ğŸ¯ Orchestrator validating workflow for session earlier-plate-compound-shop
INFO:     orchestrator.py:41    - ğŸ” State validation: âœ… PASSED
INFO:     orchestrator.py:55    - âœ… Orchestrator validation passed
INFO:     workflow.py:99    - ğŸ” Query Analysis: Analyzing user query
INFO:     query_analysis_agent.py:26    - ğŸ” Analyzing query: 'What incidents have been open the longest without ...'
INFO:     llm_client.py:117   - ğŸ” Query analyzed: incident_analysis with confidence 0.9
INFO:     llm_client.py:260   - ğŸ“‹ Tool plan created: 2 tools planned
INFO:     query_analysis_agent.py:44    - ğŸ“‹ Tool plan: [
  {
    "name": "search_incidents",
    "parameters": {
      "query": "incident open longest resolution block blocking"
    }
  },
  {
    "name": "get_incidents",
    "parameters": {}
  }
]
INFO:     query_analysis_agent.py:64    - âœ… Query analyzed: type=incident_analysis, confidence=0.9
INFO:     workflow.py:104   - ğŸ› ï¸ Tool Execution: Executing MCP tools
INFO:     tool_execution_agent.py:37    - ğŸ› ï¸ Executing 2 tools
INFO:     tool_execution_agent.py:92    - ğŸ”§ Executing search_incidents (attempt 1/2)
INFO:     mcp_client.py:251   - âœ… Created MCP client for session earlier-plate-compound-shop
INFO:     mcp_client.py:87    - ğŸ”§ Executing MCP tool: search_incidents
INFO:     mcp_client.py:93    - âœ… Tool search_incidents executed successfully
INFO:     tool_execution_agent.py:92    - ğŸ”§ Executing get_incidents (attempt 1/2)
INFO:     mcp_client.py:87    - ğŸ”§ Executing MCP tool: get_incidents
INFO:     mcp_client.py:93    - âœ… Tool get_incidents executed successfully
INFO:     tool_execution_agent.py:60    - âœ… Tool execution completed: 100.00% success rate
INFO:     workflow.py:123   - âœ¨ Response Enrichment: Enriching response
INFO:     response_enrichment_agent.py:26    - âœ¨ Enriching response
INFO:     response_enrichment_agent.py:30    - ğŸ¤– Calling LLM to generate enriched response...
INFO:     response_enrichment_agent.py:35    - ğŸŒŠ Using streaming mode for response generation
INFO:     llm_client.py:294   - ğŸ”§ Preprocessing tool: search_incidents, result keys: ['incidents', 'count', 'page', 'page_size', 'timestamp', 'tool', 'parameters', 'success']
INFO:     llm_client.py:582   - âš ï¸ No preprocessing applied for tool: search_incidents
INFO:     llm_client.py:294   - ğŸ”§ Preprocessing tool: get_incidents, result keys: ['incidents', 'count', 'count_is_exact', 'is_limited', 'timestamp', 'tool', 'parameters', 'success']
INFO:     llm_client.py:407   - ğŸš¨ Found 41 incidents
INFO:     llm_client.py:411   - ğŸ” Applying fuzzy matching with terms: ['incident', 'open', 'longest', 'resolution', 'block', 'blocking']
INFO:     llm_client.py:423   - ğŸ¯ After fuzzy matching, top incident scores: [3, 3, 3, 3, 3, 3, 3, 0, 0, 0]
INFO:     llm_client.py:428   - âœ… Processing 10 incidents
INFO:     llm_client.py:619   - Processing 2 successful tool results with search_terms: ['incident', 'open', 'longest', 'resolution', 'block', 'blocking']
INFO:     llm_client.py:624   - ğŸ“Š Preprocessed tool data size: 3418 bytes (3.3 KB)
INFO:     llm_client.py:641   - ğŸ“Š Context JSON size: 5221 bytes (5.1 KB)
INFO:     llm_client.py:642   - ğŸ“Š Estimated tokens: ~1305.25 (rough estimate)
INFO:     llm_client.py:752   - Invoking LLM for response generation...
INFO:     llm_client.py:762   - Streaming completed, total length: 1254
INFO:     response_enrichment_agent.py:41    - ğŸ” LLM response type: <class 'dict'>, value: {'final_response': 'Based on the tool results, here are the incidents that have been open the longest without resolution:\n\nâ€¢ **ID: 20 - New incident**\n  - **Severity:** Low\n  - **Status:** New\n  
INFO:     response_enrichment_agent.py:54    - ğŸ“ LLM generated response: 1254 chars
INFO:     response_enrichment_agent.py:86    - âœ… Response enrichment completed with 5 forward links
INFO:     workflow.py:138   - ğŸ¯ Orchestrator: Finalizing workflow
INFO:     workflow.py:220   - âœ… Processing completed successfully
INFO:     graph.py:141   - {"timestamp": "2025-12-01T22:52:13.352419", "uuid": "earlier-plate-compound-shop", "llm_method": "enhanced_workflow", "sent": "Based on the tool results, here are the incidents that have been open the longest without resolution"}
ERROR:     server.py:73    - {"timestamp": "2025-12-01T22:53:08.902483", "uuid": "earlier-plate-compound-shop", "op": "Error: (<CloseCode.ABNORMAL_CLOSURE: 1006>, '')"}
INFO:     server.py:77    - {"timestamp": "2025-12-01T22:53:08.902635", "uuid": "earlier-plate-compound-shop", "op": "Closing connection."}
ERROR:     server.py:82    - {"timestamp": "2025-12-01T22:53:08.902707", "uuid": "earlier-plate-compound-shop", "op": "WebSocket close error: Unexpected ASGI message 'websocket.close', after sending 'websocket.close' or response already completed."}
INFO:     server.py:53    - {"timestamp": "2025-12-01T22:53:11.907350", "uuid": null, "received": {"uuid": "earlier-plate-compound-shop", "init": true}}
INFO:     server.py:64    - {"timestamp": "2025-12-01T22:53:11.907781", "uuid": "earlier-plate-compound-shop", "op": "Initializing ws with client."}
ERROR:     server.py:73    - {"timestamp": "2025-12-01T22:53:13.051731", "uuid": "earlier-plate-compound-shop", "op": "Error: (<CloseCode.ABNORMAL_CLOSURE: 1006>, '')"}
INFO:     server.py:77    - {"timestamp": "2025-12-01T22:53:13.051884", "uuid": "earlier-plate-compound-shop", "op": "Closing connection."}
ERROR:     server.py:82    - {"timestamp": "2025-12-01T22:53:13.051957", "uuid": "earlier-plate-compound-shop", "op": "WebSocket close error: Unexpected ASGI message 'websocket.close', after sending 'websocket.close' or response already completed."}
INFO:     server.py:53    - {"timestamp": "2025-12-01T22:53:16.184987", "uuid": null, "received": {"uuid": "earlier-plate-compound-shop", "init": true}}
INFO:     server.py:64    - {"timestamp": "2025-12-01T22:53:16.185447", "uuid": "earlier-plate-compound-shop", "op": "Initializing ws with client."}
INFO:     server.py:53    - {"timestamp": "2025-12-02T08:09:13.939869", "uuid": "earlier-plate-compound-shop", "received": {"uuid": "earlier-plate-compound-shop", "message": "  describe me about the incident happened on 'Mit-runtime-api-services'", "init": false}}
INFO:     graph.py:118   - ğŸš€ Using enhanced workflow for:   describe me about the incident happened on 'Mit-...
INFO:     workflow.py:179   - ğŸš€ Processing: '  describe me about the incident happened on 'Mit-runtime-api-services''
INFO:     workflow.py:193   - ğŸ“š Found existing conversation state for thread: earlier-plate-compound-shop
INFO:     workflow.py:197   - ğŸ’¬ Loaded 2 previous messages from conversation history
INFO:     workflow.py:209   - âœ… Preserved 2 messages from previous conversation
INFO:     workflow.py:73    - ğŸ¯ Orchestrator: Starting workflow
INFO:     mcp_client.py:190   - ğŸ“‹ Fetching available MCP tools
INFO:     mcp_client.py:56    - âœ… Fetched 47 MCP tools from server
INFO:     workflow.py:80    - ğŸ“‹ Loaded 47 available MCP tools
INFO:     orchestrator.py:36    - ğŸ¯ Orchestrator validating workflow for session earlier-plate-compound-shop
INFO:     orchestrator.py:41    - ğŸ” State validation: âœ… PASSED
INFO:     orchestrator.py:55    - âœ… Orchestrator validation passed
INFO:     workflow.py:99    - ğŸ” Query Analysis: Analyzing user query
INFO:     query_analysis_agent.py:26    - ğŸ” Analyzing query: '  describe me about the incident happened on 'Mit-...'
INFO:     llm_client.py:117   - ğŸ” Query analyzed: incident_analysis with confidence 0.9
INFO:     llm_client.py:260   - ğŸ“‹ Tool plan created: 2 tools planned
INFO:     query_analysis_agent.py:44    - ğŸ“‹ Tool plan: [
  {
    "name": "search_incidents",
    "parameters": {
      "query": "runtime api services runtime-api aws aws-api runtime-aws"
    }
  },
  {
    "name": "get_incidents",
    "parameters": {}
  }
]
INFO:     query_analysis_agent.py:64    - âœ… Query analyzed: type=incident_analysis, confidence=0.9
INFO:     workflow.py:104   - ğŸ› ï¸ Tool Execution: Executing MCP tools
INFO:     tool_execution_agent.py:37    - ğŸ› ï¸ Executing 2 tools
INFO:     tool_execution_agent.py:92    - ğŸ”§ Executing search_incidents (attempt 1/2)
INFO:     mcp_client.py:87    - ğŸ”§ Executing MCP tool: search_incidents
INFO:     mcp_client.py:93    - âœ… Tool search_incidents executed successfully
INFO:     tool_execution_agent.py:92    - ğŸ”§ Executing get_incidents (attempt 1/2)
INFO:     mcp_client.py:87    - ğŸ”§ Executing MCP tool: get_incidents
INFO:     mcp_client.py:93    - âœ… Tool get_incidents executed successfully
INFO:     tool_execution_agent.py:60    - âœ… Tool execution completed: 100.00% success rate
INFO:     workflow.py:123   - âœ¨ Response Enrichment: Enriching response
INFO:     response_enrichment_agent.py:26    - âœ¨ Enriching response
INFO:     response_enrichment_agent.py:30    - ğŸ¤– Calling LLM to generate enriched response...
INFO:     response_enrichment_agent.py:35    - ğŸŒŠ Using streaming mode for response generation
INFO:     llm_client.py:294   - ğŸ”§ Preprocessing tool: search_incidents, result keys: ['incidents', 'count', 'page', 'page_size', 'timestamp', 'tool', 'parameters', 'success']
INFO:     llm_client.py:582   - âš ï¸ No preprocessing applied for tool: search_incidents
INFO:     llm_client.py:294   - ğŸ”§ Preprocessing tool: get_incidents, result keys: ['incidents', 'count', 'count_is_exact', 'is_limited', 'timestamp', 'tool', 'parameters', 'success']
INFO:     llm_client.py:407   - ğŸš¨ Found 41 incidents
INFO:     llm_client.py:411   - ğŸ” Applying fuzzy matching with terms: ['runtime', 'api', 'services', 'runtime-api', 'aws', 'aws-api', 'runtime-aws']
INFO:     llm_client.py:423   - ğŸ¯ After fuzzy matching, top incident scores: [15, 6, 3, 3, 3, 3, 3, 3, 3, 3]
INFO:     llm_client.py:428   - âœ… Processing 10 incidents
INFO:     llm_client.py:619   - Processing 2 successful tool results with search_terms: ['runtime', 'api', 'services', 'runtime-api', 'aws', 'aws-api', 'runtime-aws']
INFO:     llm_client.py:624   - ğŸ“Š Preprocessed tool data size: 3395 bytes (3.3 KB)
INFO:     llm_client.py:641   - ğŸ“Š Context JSON size: 6710 bytes (6.6 KB)
INFO:     llm_client.py:642   - ğŸ“Š Estimated tokens: ~1677.5 (rough estimate)
INFO:     llm_client.py:743   - ğŸ“œ Including 2 previous messages in context
INFO:     llm_client.py:752   - Invoking LLM for response generation...
INFO:     llm_client.py:762   - Streaming completed, total length: 673
INFO:     response_enrichment_agent.py:41    - ğŸ” LLM response type: <class 'dict'>, value: {'final_response': "I found an incident that closely matches your query about 'Mit-runtime-api-services':\n\nâ€¢ **ID: 1499 - Runtime-aws-api's are not working**\n  - **Severity:** High\n  - **Status:**
INFO:     response_enrichment_agent.py:54    - ğŸ“ LLM generated response: 673 chars
INFO:     response_enrichment_agent.py:86    - âœ… Response enrichment completed with 5 forward links
INFO:     workflow.py:138   - ğŸ¯ Orchestrator: Finalizing workflow
INFO:     workflow.py:220   - âœ… Processing completed successfully
INFO:     graph.py:141   - {"timestamp": "2025-12-02T08:09:24.594824", "uuid": "earlier-plate-compound-shop", "llm_method": "enhanced_workflow", "sent": "I found an incident that closely matches your query about 'Mit-runtime-api-services':\n\n\u2022 **ID: 1499 "}
INFO:     server.py:53    - {"timestamp": "2025-12-02T08:09:41.390495", "uuid": "earlier-plate-compound-shop", "received": {"uuid": "earlier-plate-compound-shop", "message": "  describe me about the incident happened on 'Mit-runtime-api-services'", "init": false}}
INFO:     graph.py:118   - ğŸš€ Using enhanced workflow for:   describe me about the incident happened on 'Mit-...
INFO:     workflow.py:179   - ğŸš€ Processing: '  describe me about the incident happened on 'Mit-runtime-api-services''
INFO:     workflow.py:193   - ğŸ“š Found existing conversation state for thread: earlier-plate-compound-shop
INFO:     workflow.py:197   - ğŸ’¬ Loaded 4 previous messages from conversation history
INFO:     workflow.py:209   - âœ… Preserved 4 messages from previous conversation
INFO:     workflow.py:73    - ğŸ¯ Orchestrator: Starting workflow
INFO:     mcp_client.py:190   - ğŸ“‹ Fetching available MCP tools
INFO:     workflow.py:80    - ğŸ“‹ Loaded 47 available MCP tools
INFO:     orchestrator.py:36    - ğŸ¯ Orchestrator validating workflow for session earlier-plate-compound-shop
INFO:     orchestrator.py:41    - ğŸ” State validation: âœ… PASSED
INFO:     orchestrator.py:55    - âœ… Orchestrator validation passed
INFO:     workflow.py:99    - ğŸ” Query Analysis: Analyzing user query
INFO:     query_analysis_agent.py:26    - ğŸ” Analyzing query: '  describe me about the incident happened on 'Mit-...'
INFO:     llm_client.py:117   - ğŸ” Query analyzed: incident_analysis with confidence 0.9
INFO:     llm_client.py:260   - ğŸ“‹ Tool plan created: 2 tools planned
INFO:     query_analysis_agent.py:44    - ğŸ“‹ Tool plan: [
  {
    "name": "search_incidents",
    "parameters": {
      "query": "runtime api services runtime-api aws aws-api runtime-aws"
    }
  },
  {
    "name": "get_incidents",
    "parameters": {}
  }
]
INFO:     query_analysis_agent.py:64    - âœ… Query analyzed: type=incident_analysis, confidence=0.9
INFO:     workflow.py:104   - ğŸ› ï¸ Tool Execution: Executing MCP tools
INFO:     tool_execution_agent.py:37    - ğŸ› ï¸ Executing 2 tools
INFO:     tool_execution_agent.py:92    - ğŸ”§ Executing search_incidents (attempt 1/2)
INFO:     mcp_client.py:87    - ğŸ”§ Executing MCP tool: search_incidents
INFO:     mcp_client.py:93    - âœ… Tool search_incidents executed successfully
INFO:     tool_execution_agent.py:92    - ğŸ”§ Executing get_incidents (attempt 1/2)
INFO:     mcp_client.py:87    - ğŸ”§ Executing MCP tool: get_incidents
INFO:     mcp_client.py:93    - âœ… Tool get_incidents executed successfully
INFO:     tool_execution_agent.py:60    - âœ… Tool execution completed: 100.00% success rate
INFO:     workflow.py:123   - âœ¨ Response Enrichment: Enriching response
INFO:     response_enrichment_agent.py:26    - âœ¨ Enriching response
INFO:     response_enrichment_agent.py:30    - ğŸ¤– Calling LLM to generate enriched response...
INFO:     response_enrichment_agent.py:35    - ğŸŒŠ Using streaming mode for response generation
INFO:     llm_client.py:294   - ğŸ”§ Preprocessing tool: search_incidents, result keys: ['incidents', 'count', 'page', 'page_size', 'timestamp', 'tool', 'parameters', 'success']
INFO:     llm_client.py:582   - âš ï¸ No preprocessing applied for tool: search_incidents
INFO:     llm_client.py:294   - ğŸ”§ Preprocessing tool: get_incidents, result keys: ['incidents', 'count', 'count_is_exact', 'is_limited', 'timestamp', 'tool', 'parameters', 'success']
INFO:     llm_client.py:407   - ğŸš¨ Found 41 incidents
INFO:     llm_client.py:411   - ğŸ” Applying fuzzy matching with terms: ['runtime', 'api', 'services', 'runtime-api', 'aws', 'aws-api', 'runtime-aws']
INFO:     llm_client.py:423   - ğŸ¯ After fuzzy matching, top incident scores: [15, 6, 3, 3, 3, 3, 3, 3, 3, 3]
INFO:     llm_client.py:428   - âœ… Processing 10 incidents
INFO:     llm_client.py:619   - Processing 2 successful tool results with search_terms: ['runtime', 'api', 'services', 'runtime-api', 'aws', 'aws-api', 'runtime-aws']
INFO:     llm_client.py:624   - ğŸ“Š Preprocessed tool data size: 3395 bytes (3.3 KB)
INFO:     llm_client.py:641   - ğŸ“Š Context JSON size: 7584 bytes (7.4 KB)
INFO:     llm_client.py:642   - ğŸ“Š Estimated tokens: ~1896.0 (rough estimate)
INFO:     llm_client.py:743   - ğŸ“œ Including 4 previous messages in context
INFO:     llm_client.py:752   - Invoking LLM for response generation...
INFO:     llm_client.py:762   - Streaming completed, total length: 672
INFO:     response_enrichment_agent.py:41    - ğŸ” LLM response type: <class 'dict'>, value: {'final_response': "I found an incident that is relevant to your query about 'Mit-runtime-api-services':\n\nâ€¢ **ID: 1499 - Runtime-aws-api's are not working**\n  - **Severity:** High\n  - **Status:** 
INFO:     response_enrichment_agent.py:54    - ğŸ“ LLM generated response: 672 chars
INFO:     response_enrichment_agent.py:86    - âœ… Response enrichment completed with 5 forward links
INFO:     workflow.py:138   - ğŸ¯ Orchestrator: Finalizing workflow
INFO:     workflow.py:220   - âœ… Processing completed successfully
INFO:     graph.py:141   - {"timestamp": "2025-12-02T08:09:51.141203", "uuid": "earlier-plate-compound-shop", "llm_method": "enhanced_workflow", "sent": "I found an incident that is relevant to your query about 'Mit-runtime-api-services':\n\n\u2022 **ID: 1499 -"}
ERROR:     server.py:73    - {"timestamp": "2025-12-02T08:09:55.367263", "uuid": "earlier-plate-compound-shop", "op": "Error: (<CloseCode.ABNORMAL_CLOSURE: 1006>, '')"}
INFO:     server.py:77    - {"timestamp": "2025-12-02T08:09:55.368272", "uuid": "earlier-plate-compound-shop", "op": "Closing connection."}
ERROR:     server.py:82    - {"timestamp": "2025-12-02T08:09:55.368712", "uuid": "earlier-plate-compound-shop", "op": "WebSocket close error: Unexpected ASGI message 'websocket.close', after sending 'websocket.close' or response already completed."}
INFO:     server.py:53    - {"timestamp": "2025-12-02T08:09:58.809026", "uuid": null, "received": {"uuid": "earlier-plate-compound-shop", "init": true}}
INFO:     server.py:64    - {"timestamp": "2025-12-02T08:09:58.809475", "uuid": "earlier-plate-compound-shop", "op": "Initializing ws with client."}
