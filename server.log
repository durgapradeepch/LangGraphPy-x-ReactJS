INFO:     llm_client.py:35    - âœ… LLM client initialized with model: gpt-4o
INFO:     cust_logger.py:68    - Set message color for graph.py to MAGENTA
INFO:     cust_logger.py:68    - Set message color for server.py to PURPLE
INFO:     server.py:53    - {"timestamp": "2025-12-01T22:51:34.184765", "uuid": null, "received": {"uuid": "earlier-plate-compound-shop", "init": true}}
INFO:     server.py:64    - {"timestamp": "2025-12-01T22:51:34.185127", "uuid": "earlier-plate-compound-shop", "op": "Initializing ws with client."}
INFO:     server.py:53    - {"timestamp": "2025-12-01T22:51:59.292700", "uuid": "earlier-plate-compound-shop", "received": {"uuid": "earlier-plate-compound-shop", "message": "What incidents have been open the longest without resolution and what's blocking them?", "init": false}}
INFO:     graph.py:118   - ğŸš€ Using enhanced workflow for: What incidents have been open the longest without ...
INFO:     workflow.py:179   - ğŸš€ Processing: 'What incidents have been open the longest without resolution and what's blocking them?'
INFO:     workflow.py:73    - ğŸ¯ Orchestrator: Starting workflow
INFO:     mcp_client.py:251   - âœ… Created MCP client for session default
INFO:     mcp_client.py:190   - ğŸ“‹ Fetching available MCP tools
INFO:     mcp_client.py:56    - âœ… Fetched 47 MCP tools from server
INFO:     workflow.py:80    - ğŸ“‹ Loaded 47 available MCP tools
INFO:     orchestrator.py:36    - ğŸ¯ Orchestrator validating workflow for session earlier-plate-compound-shop
INFO:     orchestrator.py:41    - ğŸ” State validation: âœ… PASSED
INFO:     orchestrator.py:55    - âœ… Orchestrator validation passed
INFO:     workflow.py:99    - ğŸ” Query Analysis: Analyzing user query
INFO:     query_analysis_agent.py:26    - ğŸ” Analyzing query: 'What incidents have been open the longest without ...'
INFO:     llm_client.py:117   - ğŸ” Query analyzed: incident_analysis with confidence 0.9
INFO:     llm_client.py:260   - ğŸ“‹ Tool plan created: 2 tools planned
INFO:     query_analysis_agent.py:44    - ğŸ“‹ Tool plan: [
  {
    "name": "search_incidents",
    "parameters": {
      "query": "incident open longest resolution block blocking"
    }
  },
  {
    "name": "get_incidents",
    "parameters": {}
  }
]
INFO:     query_analysis_agent.py:64    - âœ… Query analyzed: type=incident_analysis, confidence=0.9
INFO:     workflow.py:104   - ğŸ› ï¸ Tool Execution: Executing MCP tools
INFO:     tool_execution_agent.py:37    - ğŸ› ï¸ Executing 2 tools
INFO:     tool_execution_agent.py:92    - ğŸ”§ Executing search_incidents (attempt 1/2)
INFO:     mcp_client.py:251   - âœ… Created MCP client for session earlier-plate-compound-shop
INFO:     mcp_client.py:87    - ğŸ”§ Executing MCP tool: search_incidents
INFO:     mcp_client.py:93    - âœ… Tool search_incidents executed successfully
INFO:     tool_execution_agent.py:92    - ğŸ”§ Executing get_incidents (attempt 1/2)
INFO:     mcp_client.py:87    - ğŸ”§ Executing MCP tool: get_incidents
INFO:     mcp_client.py:93    - âœ… Tool get_incidents executed successfully
INFO:     tool_execution_agent.py:60    - âœ… Tool execution completed: 100.00% success rate
INFO:     workflow.py:123   - âœ¨ Response Enrichment: Enriching response
INFO:     response_enrichment_agent.py:26    - âœ¨ Enriching response
INFO:     response_enrichment_agent.py:30    - ğŸ¤– Calling LLM to generate enriched response...
INFO:     response_enrichment_agent.py:35    - ğŸŒŠ Using streaming mode for response generation
INFO:     llm_client.py:294   - ğŸ”§ Preprocessing tool: search_incidents, result keys: ['incidents', 'count', 'page', 'page_size', 'timestamp', 'tool', 'parameters', 'success']
INFO:     llm_client.py:582   - âš ï¸ No preprocessing applied for tool: search_incidents
INFO:     llm_client.py:294   - ğŸ”§ Preprocessing tool: get_incidents, result keys: ['incidents', 'count', 'count_is_exact', 'is_limited', 'timestamp', 'tool', 'parameters', 'success']
INFO:     llm_client.py:407   - ğŸš¨ Found 41 incidents
INFO:     llm_client.py:411   - ğŸ” Applying fuzzy matching with terms: ['incident', 'open', 'longest', 'resolution', 'block', 'blocking']
INFO:     llm_client.py:423   - ğŸ¯ After fuzzy matching, top incident scores: [3, 3, 3, 3, 3, 3, 3, 0, 0, 0]
INFO:     llm_client.py:428   - âœ… Processing 10 incidents
INFO:     llm_client.py:619   - Processing 2 successful tool results with search_terms: ['incident', 'open', 'longest', 'resolution', 'block', 'blocking']
INFO:     llm_client.py:624   - ğŸ“Š Preprocessed tool data size: 3418 bytes (3.3 KB)
INFO:     llm_client.py:641   - ğŸ“Š Context JSON size: 5221 bytes (5.1 KB)
INFO:     llm_client.py:642   - ğŸ“Š Estimated tokens: ~1305.25 (rough estimate)
INFO:     llm_client.py:752   - Invoking LLM for response generation...
INFO:     llm_client.py:762   - Streaming completed, total length: 1254
INFO:     response_enrichment_agent.py:41    - ğŸ” LLM response type: <class 'dict'>, value: {'final_response': 'Based on the tool results, here are the incidents that have been open the longest without resolution:\n\nâ€¢ **ID: 20 - New incident**\n  - **Severity:** Low\n  - **Status:** New\n  
INFO:     response_enrichment_agent.py:54    - ğŸ“ LLM generated response: 1254 chars
INFO:     response_enrichment_agent.py:86    - âœ… Response enrichment completed with 5 forward links
INFO:     workflow.py:138   - ğŸ¯ Orchestrator: Finalizing workflow
INFO:     workflow.py:220   - âœ… Processing completed successfully
INFO:     graph.py:141   - {"timestamp": "2025-12-01T22:52:13.352419", "uuid": "earlier-plate-compound-shop", "llm_method": "enhanced_workflow", "sent": "Based on the tool results, here are the incidents that have been open the longest without resolution"}
